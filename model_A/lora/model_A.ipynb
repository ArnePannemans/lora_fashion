{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2KuDe2tjxqbG",
    "outputId": "d71a8af7-2e39-4a2b-97cc-59f3aa10dc6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'ai-toolkit' already exists and is not an empty directory.\n",
      "Collecting git+https://github.com/huggingface/diffusers.git (from -r ai-toolkit/requirements.txt (line 4))\n",
      "  Cloning https://github.com/huggingface/diffusers.git to /tmp/pip-req-build-8ttqdf4k\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/diffusers.git /tmp/pip-req-build-8ttqdf4k\n",
      "  Resolved https://github.com/huggingface/diffusers.git to commit fddbab79932eedf1a78041ef38c47df80ab84c90\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from -r ai-toolkit/requirements.txt (line 1)) (2.4.1+cu124)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from -r ai-toolkit/requirements.txt (line 2)) (0.19.1+cu124)\n",
      "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from -r ai-toolkit/requirements.txt (line 3)) (0.4.5)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from -r ai-toolkit/requirements.txt (line 5)) (4.46.0)\n",
      "Requirement already satisfied: lycoris-lora==1.8.3 in /usr/local/lib/python3.11/dist-packages (from -r ai-toolkit/requirements.txt (line 6)) (1.8.3)\n",
      "Requirement already satisfied: flatten_json in /usr/local/lib/python3.11/dist-packages (from -r ai-toolkit/requirements.txt (line 7)) (0.1.14)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from -r ai-toolkit/requirements.txt (line 8)) (6.0.2)\n",
      "Requirement already satisfied: oyaml in /usr/local/lib/python3.11/dist-packages (from -r ai-toolkit/requirements.txt (line 9)) (1.0)\n",
      "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (from -r ai-toolkit/requirements.txt (line 10)) (2.18.0)\n",
      "Requirement already satisfied: kornia in /usr/local/lib/python3.11/dist-packages (from -r ai-toolkit/requirements.txt (line 11)) (0.7.3)\n",
      "Requirement already satisfied: invisible-watermark in /usr/local/lib/python3.11/dist-packages (from -r ai-toolkit/requirements.txt (line 12)) (0.2.0)\n",
      "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from -r ai-toolkit/requirements.txt (line 13)) (0.8.0)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (from -r ai-toolkit/requirements.txt (line 14)) (1.0.1)\n",
      "Requirement already satisfied: toml in /usr/local/lib/python3.11/dist-packages (from -r ai-toolkit/requirements.txt (line 15)) (0.10.2)\n",
      "Requirement already satisfied: albumentations==1.4.15 in /usr/local/lib/python3.11/dist-packages (from -r ai-toolkit/requirements.txt (line 16)) (1.4.15)\n",
      "Requirement already satisfied: albucore==0.0.16 in /usr/local/lib/python3.11/dist-packages (from -r ai-toolkit/requirements.txt (line 17)) (0.0.16)\n",
      "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from -r ai-toolkit/requirements.txt (line 18)) (2.9.2)\n",
      "Requirement already satisfied: omegaconf in /usr/local/lib/python3.11/dist-packages (from -r ai-toolkit/requirements.txt (line 19)) (2.3.0)\n",
      "Requirement already satisfied: k-diffusion in /usr/local/lib/python3.11/dist-packages (from -r ai-toolkit/requirements.txt (line 20)) (0.1.1.post1)\n",
      "Requirement already satisfied: open_clip_torch in /usr/local/lib/python3.11/dist-packages (from -r ai-toolkit/requirements.txt (line 21)) (2.28.0)\n",
      "Requirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (from -r ai-toolkit/requirements.txt (line 22)) (1.0.11)\n",
      "Requirement already satisfied: prodigyopt in /usr/local/lib/python3.11/dist-packages (from -r ai-toolkit/requirements.txt (line 23)) (1.0)\n",
      "Requirement already satisfied: controlnet_aux==0.0.7 in /usr/local/lib/python3.11/dist-packages (from -r ai-toolkit/requirements.txt (line 24)) (0.0.7)\n",
      "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (from -r ai-toolkit/requirements.txt (line 25)) (1.0.1)\n",
      "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (from -r ai-toolkit/requirements.txt (line 26)) (0.44.1)\n",
      "Requirement already satisfied: hf_transfer in /usr/local/lib/python3.11/dist-packages (from -r ai-toolkit/requirements.txt (line 27)) (0.1.8)\n",
      "Requirement already satisfied: lpips in /usr/local/lib/python3.11/dist-packages (from -r ai-toolkit/requirements.txt (line 28)) (0.1.4)\n",
      "Requirement already satisfied: pytorch_fid in /usr/local/lib/python3.11/dist-packages (from -r ai-toolkit/requirements.txt (line 29)) (0.3.0)\n",
      "Requirement already satisfied: optimum-quanto==0.2.4 in /usr/local/lib/python3.11/dist-packages (from -r ai-toolkit/requirements.txt (line 30)) (0.2.4)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from -r ai-toolkit/requirements.txt (line 31)) (0.2.0)\n",
      "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from -r ai-toolkit/requirements.txt (line 32)) (0.26.1)\n",
      "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (from -r ai-toolkit/requirements.txt (line 33)) (0.13.2)\n",
      "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (from -r ai-toolkit/requirements.txt (line 34)) (5.4.0)\n",
      "Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from -r ai-toolkit/requirements.txt (line 35)) (8.0.4)\n",
      "Requirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.11/dist-packages (from albumentations==1.4.15->-r ai-toolkit/requirements.txt (line 16)) (1.26.3)\n",
      "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from albumentations==1.4.15->-r ai-toolkit/requirements.txt (line 16)) (1.14.1)\n",
      "Requirement already satisfied: scikit-image>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from albumentations==1.4.15->-r ai-toolkit/requirements.txt (line 16)) (0.24.0)\n",
      "Requirement already satisfied: eval-type-backport in /usr/local/lib/python3.11/dist-packages (from albumentations==1.4.15->-r ai-toolkit/requirements.txt (line 16)) (0.2.0)\n",
      "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.11/dist-packages (from albumentations==1.4.15->-r ai-toolkit/requirements.txt (line 16)) (4.10.0.84)\n",
      "Requirement already satisfied: importlib-metadata in /usr/lib/python3/dist-packages (from controlnet_aux==0.0.7->-r ai-toolkit/requirements.txt (line 24)) (4.6.4)\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from controlnet_aux==0.0.7->-r ai-toolkit/requirements.txt (line 24)) (4.10.0.84)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from controlnet_aux==0.0.7->-r ai-toolkit/requirements.txt (line 24)) (3.13.1)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from controlnet_aux==0.0.7->-r ai-toolkit/requirements.txt (line 24)) (10.2.0)\n",
      "Requirement already satisfied: ninja in /usr/local/lib/python3.11/dist-packages (from optimum-quanto==0.2.4->-r ai-toolkit/requirements.txt (line 30)) (1.11.1.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r ai-toolkit/requirements.txt (line 1)) (4.9.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch->-r ai-toolkit/requirements.txt (line 1)) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->-r ai-toolkit/requirements.txt (line 1)) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->-r ai-toolkit/requirements.txt (line 1)) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->-r ai-toolkit/requirements.txt (line 1)) (2024.2.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.99 in /usr/local/lib/python3.11/dist-packages (from torch->-r ai-toolkit/requirements.txt (line 1)) (12.4.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.99 in /usr/local/lib/python3.11/dist-packages (from torch->-r ai-toolkit/requirements.txt (line 1)) (12.4.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.99 in /usr/local/lib/python3.11/dist-packages (from torch->-r ai-toolkit/requirements.txt (line 1)) (12.4.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->-r ai-toolkit/requirements.txt (line 1)) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.2.65 in /usr/local/lib/python3.11/dist-packages (from torch->-r ai-toolkit/requirements.txt (line 1)) (12.4.2.65)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.0.44 in /usr/local/lib/python3.11/dist-packages (from torch->-r ai-toolkit/requirements.txt (line 1)) (11.2.0.44)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.119 in /usr/local/lib/python3.11/dist-packages (from torch->-r ai-toolkit/requirements.txt (line 1)) (10.3.5.119)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.0.99 in /usr/local/lib/python3.11/dist-packages (from torch->-r ai-toolkit/requirements.txt (line 1)) (11.6.0.99)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.0.142 in /usr/local/lib/python3.11/dist-packages (from torch->-r ai-toolkit/requirements.txt (line 1)) (12.3.0.142)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.11/dist-packages (from torch->-r ai-toolkit/requirements.txt (line 1)) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.99 in /usr/local/lib/python3.11/dist-packages (from torch->-r ai-toolkit/requirements.txt (line 1)) (12.4.99)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.99 in /usr/local/lib/python3.11/dist-packages (from torch->-r ai-toolkit/requirements.txt (line 1)) (12.4.99)\n",
      "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r ai-toolkit/requirements.txt (line 1)) (3.0.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from diffusers==0.32.0.dev0->-r ai-toolkit/requirements.txt (line 4)) (2024.9.11)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from diffusers==0.32.0.dev0->-r ai-toolkit/requirements.txt (line 4)) (2.32.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers->-r ai-toolkit/requirements.txt (line 5)) (24.1)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.11/dist-packages (from transformers->-r ai-toolkit/requirements.txt (line 5)) (0.20.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers->-r ai-toolkit/requirements.txt (line 5)) (4.66.5)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from flatten_json->-r ai-toolkit/requirements.txt (line 7)) (1.16.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r ai-toolkit/requirements.txt (line 10)) (2.1.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r ai-toolkit/requirements.txt (line 10)) (1.67.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r ai-toolkit/requirements.txt (line 10)) (3.7)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r ai-toolkit/requirements.txt (line 10)) (5.28.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r ai-toolkit/requirements.txt (line 10)) (75.1.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r ai-toolkit/requirements.txt (line 10)) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r ai-toolkit/requirements.txt (line 10)) (3.0.6)\n",
      "Requirement already satisfied: kornia-rs>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from kornia->-r ai-toolkit/requirements.txt (line 11)) (0.1.5)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from invisible-watermark->-r ai-toolkit/requirements.txt (line 12)) (1.7.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate->-r ai-toolkit/requirements.txt (line 14)) (6.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->-r ai-toolkit/requirements.txt (line 18)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.11/dist-packages (from pydantic->-r ai-toolkit/requirements.txt (line 18)) (2.23.4)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from omegaconf->-r ai-toolkit/requirements.txt (line 19)) (4.9.3)\n",
      "Requirement already satisfied: clean-fid in /usr/local/lib/python3.11/dist-packages (from k-diffusion->-r ai-toolkit/requirements.txt (line 20)) (0.1.35)\n",
      "Requirement already satisfied: clip-anytorch in /usr/local/lib/python3.11/dist-packages (from k-diffusion->-r ai-toolkit/requirements.txt (line 20)) (2.6.0)\n",
      "Requirement already satisfied: dctorch in /usr/local/lib/python3.11/dist-packages (from k-diffusion->-r ai-toolkit/requirements.txt (line 20)) (0.1.2)\n",
      "Requirement already satisfied: jsonmerge in /usr/local/lib/python3.11/dist-packages (from k-diffusion->-r ai-toolkit/requirements.txt (line 20)) (1.9.2)\n",
      "Requirement already satisfied: torchdiffeq in /usr/local/lib/python3.11/dist-packages (from k-diffusion->-r ai-toolkit/requirements.txt (line 20)) (0.2.4)\n",
      "Requirement already satisfied: torchsde in /usr/local/lib/python3.11/dist-packages (from k-diffusion->-r ai-toolkit/requirements.txt (line 20)) (0.2.6)\n",
      "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (from k-diffusion->-r ai-toolkit/requirements.txt (line 20)) (0.18.5)\n",
      "Requirement already satisfied: ftfy in /usr/local/lib/python3.11/dist-packages (from open_clip_torch->-r ai-toolkit/requirements.txt (line 21)) (6.3.1)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio->-r ai-toolkit/requirements.txt (line 34)) (23.2.1)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio->-r ai-toolkit/requirements.txt (line 34)) (4.6.0)\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio->-r ai-toolkit/requirements.txt (line 34)) (0.115.3)\n",
      "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio->-r ai-toolkit/requirements.txt (line 34)) (0.4.0)\n",
      "Requirement already satisfied: gradio-client==1.4.2 in /usr/local/lib/python3.11/dist-packages (from gradio->-r ai-toolkit/requirements.txt (line 34)) (1.4.2)\n",
      "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio->-r ai-toolkit/requirements.txt (line 34)) (0.27.2)\n",
      "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio->-r ai-toolkit/requirements.txt (line 34)) (2.1.5)\n",
      "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio->-r ai-toolkit/requirements.txt (line 34)) (3.10.10)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio->-r ai-toolkit/requirements.txt (line 34)) (2.2.3)\n",
      "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio->-r ai-toolkit/requirements.txt (line 34)) (0.25.1)\n",
      "Requirement already satisfied: python-multipart==0.0.12 in /usr/local/lib/python3.11/dist-packages (from gradio->-r ai-toolkit/requirements.txt (line 34)) (0.0.12)\n",
      "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.11/dist-packages (from gradio->-r ai-toolkit/requirements.txt (line 34)) (0.7.1)\n",
      "Requirement already satisfied: safehttpx<1.0,>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from gradio->-r ai-toolkit/requirements.txt (line 34)) (0.1.1)\n",
      "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio->-r ai-toolkit/requirements.txt (line 34)) (2.10.0)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio->-r ai-toolkit/requirements.txt (line 34)) (0.41.0)\n",
      "Requirement already satisfied: tomlkit==0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio->-r ai-toolkit/requirements.txt (line 34)) (0.12.0)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio->-r ai-toolkit/requirements.txt (line 34)) (0.12.5)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio->-r ai-toolkit/requirements.txt (line 34)) (0.32.0)\n",
      "Requirement already satisfied: websockets<13.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.4.2->gradio->-r ai-toolkit/requirements.txt (line 34)) (12.0)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.11/dist-packages (from python-slugify->-r ai-toolkit/requirements.txt (line 35)) (1.3)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio->-r ai-toolkit/requirements.txt (line 34)) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio->-r ai-toolkit/requirements.txt (line 34)) (1.3.1)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio->-r ai-toolkit/requirements.txt (line 34)) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio->-r ai-toolkit/requirements.txt (line 34)) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio->-r ai-toolkit/requirements.txt (line 34)) (0.14.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio->-r ai-toolkit/requirements.txt (line 34)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio->-r ai-toolkit/requirements.txt (line 34)) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio->-r ai-toolkit/requirements.txt (line 34)) (2024.2)\n",
      "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.21.0->albumentations==1.4.15->-r ai-toolkit/requirements.txt (line 16)) (2.36.0)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.21.0->albumentations==1.4.15->-r ai-toolkit/requirements.txt (line 16)) (2024.9.20)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.21.0->albumentations==1.4.15->-r ai-toolkit/requirements.txt (line 16)) (0.4)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio->-r ai-toolkit/requirements.txt (line 34)) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio->-r ai-toolkit/requirements.txt (line 34)) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio->-r ai-toolkit/requirements.txt (line 34)) (13.9.3)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy->open_clip_torch->-r ai-toolkit/requirements.txt (line 21)) (0.2.13)\n",
      "Requirement already satisfied: jsonschema>2.4.0 in /usr/local/lib/python3.11/dist-packages (from jsonmerge->k-diffusion->-r ai-toolkit/requirements.txt (line 20)) (4.23.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.32.0.dev0->-r ai-toolkit/requirements.txt (line 4)) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.32.0.dev0->-r ai-toolkit/requirements.txt (line 4)) (2.2.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.11/dist-packages (from sympy->torch->-r ai-toolkit/requirements.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: trampoline>=0.1.2 in /usr/local/lib/python3.11/dist-packages (from torchsde->k-diffusion->-r ai-toolkit/requirements.txt (line 20)) (0.1.2)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb->k-diffusion->-r ai-toolkit/requirements.txt (line 20)) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->k-diffusion->-r ai-toolkit/requirements.txt (line 20)) (3.1.43)\n",
      "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb->k-diffusion->-r ai-toolkit/requirements.txt (line 20)) (4.3.6)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->k-diffusion->-r ai-toolkit/requirements.txt (line 20)) (2.17.0)\n",
      "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb->k-diffusion->-r ai-toolkit/requirements.txt (line 20)) (1.3.3)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->k-diffusion->-r ai-toolkit/requirements.txt (line 20)) (4.0.11)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>2.4.0->jsonmerge->k-diffusion->-r ai-toolkit/requirements.txt (line 20)) (24.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>2.4.0->jsonmerge->k-diffusion->-r ai-toolkit/requirements.txt (line 20)) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>2.4.0->jsonmerge->k-diffusion->-r ai-toolkit/requirements.txt (line 20)) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>2.4.0->jsonmerge->k-diffusion->-r ai-toolkit/requirements.txt (line 20)) (0.20.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio->-r ai-toolkit/requirements.txt (line 34)) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio->-r ai-toolkit/requirements.txt (line 34)) (2.18.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->k-diffusion->-r ai-toolkit/requirements.txt (line 20)) (5.0.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio->-r ai-toolkit/requirements.txt (line 34)) (0.1.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/ostris/ai-toolkit.git\n",
    "!cd ai-toolkit && git submodule update --init --recursive\n",
    "!pip install -r ai-toolkit/requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "9pWOX1PpxzRh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "The token `flux_lora_ml6` has been saved to /root/.cache/huggingface/stored_tokens\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful.\n",
      "The current active token is: `flux_lora_ml6`\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli login --token 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"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "KTn9PdqZx96r"
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "INPUT_FOLDER = \"model_A\"\n",
    "OUTPUT_FOLDER = INPUT_FOLDER + \"_output_lower_lr\"\n",
    "TRIGGER_WORD = INPUT_FOLDER\n",
    "LORA_RANK = 64\n",
    "BATCHSIZE = 8\n",
    "LEARNING_RATE = 0.0001\n",
    "STEPS_TRAIN = 3000\n",
    "STEPS_SAVE = 100\n",
    "STEPS_SAMPLE = 100\n",
    "\n",
    "# Configure the training job\n",
    "job_to_run = OrderedDict([\n",
    "    ('job', 'extension'),\n",
    "    ('config', OrderedDict([\n",
    "        ('name', 'model_A_lora_v1'),\n",
    "        ('process', [\n",
    "            OrderedDict([\n",
    "                ('type', 'sd_trainer'),\n",
    "                ('training_folder', OUTPUT_FOLDER),\n",
    "                ('performance_log_every', 100),\n",
    "                ('device', 'cuda:0'),  # Use GPU\n",
    "                ('trigger_word', TRIGGER_WORD),\n",
    "                ('network', OrderedDict([\n",
    "                    ('type', 'lora'),\n",
    "                    ('linear', LORA_RANK),\n",
    "                    ('linear_alpha', LORA_RANK)\n",
    "                ])),\n",
    "                ('save', OrderedDict([\n",
    "                    ('dtype', 'float16'),  # Precision for saving\n",
    "                    ('save_every', STEPS_SAVE),  # Save every X steps\n",
    "                    ('max_step_saves_to_keep', 30)  # Keep last 10 checkpoints\n",
    "                ])),\n",
    "                ('datasets', [\n",
    "                    OrderedDict([\n",
    "                        ('folder_path', INPUT_FOLDER),\n",
    "                        ('caption_ext', 'txt'),  # Caption extension must match txt files\n",
    "                        ('caption_dropout_rate', 0.005),  # Dropout 5% of captions for diversity\n",
    "                        ('shuffle_tokens', False),  # Do not shuffle caption tokens\n",
    "                        ('cache_latents_to_disk', True),  # Cache latents to disk for efficiency\n",
    "                        ('resolution', [768, 1024])\n",
    "                    ])\n",
    "                ]),\n",
    "                ('train', OrderedDict([\n",
    "                    ('batch_size', BATCHSIZE),\n",
    "                    ('steps', STEPS_TRAIN),\n",
    "                    ('gradient_accumulation_steps', 1),\n",
    "                    ('train_unet', True),\n",
    "                    ('train_text_encoder', False),\n",
    "                    ('content_or_style', 'balanced'),\n",
    "                    ('gradient_checkpointing', True),\n",
    "                    ('noise_scheduler', 'flowmatch'),\n",
    "                    ('optimizer', 'adamw8bit'),\n",
    "                    ('lr', LEARNING_RATE),\n",
    "                    ('lr_scheduler', 'cosine'),  \n",
    "                    ('scheduler_params', OrderedDict([\n",
    "                        ('T_max', STEPS_TRAIN), \n",
    "                        ('eta_min', 0.000005)\n",
    "                    ])),\n",
    "                    ('ema_config', OrderedDict([\n",
    "                        ('use_ema', True),\n",
    "                        ('ema_decay', 0.99)\n",
    "                    ])),\n",
    "                    ('dtype', 'bf16')\n",
    "                ])),\n",
    "                ('model', OrderedDict([\n",
    "                    ('name_or_path', 'black-forest-labs/FLUX.1-dev'),\n",
    "                    ('is_flux', True),\n",
    "                    ('quantize', True)\n",
    "                ])),\n",
    "                ('sample', OrderedDict([\n",
    "                    ('sampler', 'flowmatch'),  # Use flowmatch sampler\n",
    "                    ('sample_every', STEPS_SAMPLE),  # Generate sample every 250 steps\n",
    "                    ('width', 768),\n",
    "                    ('height', 768),\n",
    "                    ('prompts', [\n",
    "                        f'A portrait of male model {TRIGGER_WORD} wearing a red sweater.',\n",
    "                        f'A male model, {TRIGGER_WORD}, sits with a poised and relaxed demeanor, one arm resting on the chairs arm, dressed in a sleek dark suit paired with a crisp white shirt. His tie displays a subtle pattern, adding a touch of elegance. The plain, light-colored background keeps the focus on his attire'\n",
    "                    ]),\n",
    "                    ('neg', ''),\n",
    "                    ('seed', 42),\n",
    "                    ('walk_seed', True),\n",
    "                    ('guidance_scale', 4),  # Set guidance scale\n",
    "                    ('sample_steps', 20)  # Number of steps for sampling\n",
    "                ]))\n",
    "            ])\n",
    "        ])\n",
    "    ])),\n",
    "    ('meta', OrderedDict([\n",
    "        ('name', '[name]'),\n",
    "        ('version', '1.0')\n",
    "    ]))\n",
    "])\n",
    "\n",
    "# Import necessary modules and start training\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('ai-toolkit')\n",
    "from toolkit.job import run_job\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_PiATolLxgW9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.20 (you have 1.4.15). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n",
      "/usr/local/lib/python3.11/dist-packages/controlnet_aux/mediapipe_face/mediapipe_face_common.py:7: UserWarning: The module 'mediapipe' is not installed. The package will have limited functionality. Please install it using the command: pip install 'mediapipe'\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
      "/usr/local/lib/python3.11/dist-packages/timm/models/registry.py:4: FutureWarning: Importing from timm.models.registry is deprecated, please import via timm.models\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n",
      "/usr/local/lib/python3.11/dist-packages/controlnet_aux/segment_anything/modeling/tiny_vit_sam.py:654: UserWarning: Overwriting tiny_vit_5m_224 in registry with controlnet_aux.segment_anything.modeling.tiny_vit_sam.tiny_vit_5m_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  return register_model(fn_wrapper)\n",
      "/usr/local/lib/python3.11/dist-packages/controlnet_aux/segment_anything/modeling/tiny_vit_sam.py:654: UserWarning: Overwriting tiny_vit_11m_224 in registry with controlnet_aux.segment_anything.modeling.tiny_vit_sam.tiny_vit_11m_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  return register_model(fn_wrapper)\n",
      "/usr/local/lib/python3.11/dist-packages/controlnet_aux/segment_anything/modeling/tiny_vit_sam.py:654: UserWarning: Overwriting tiny_vit_21m_224 in registry with controlnet_aux.segment_anything.modeling.tiny_vit_sam.tiny_vit_21m_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  return register_model(fn_wrapper)\n",
      "/usr/local/lib/python3.11/dist-packages/controlnet_aux/segment_anything/modeling/tiny_vit_sam.py:654: UserWarning: Overwriting tiny_vit_21m_384 in registry with controlnet_aux.segment_anything.modeling.tiny_vit_sam.tiny_vit_21m_384. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  return register_model(fn_wrapper)\n",
      "/usr/local/lib/python3.11/dist-packages/controlnet_aux/segment_anything/modeling/tiny_vit_sam.py:654: UserWarning: Overwriting tiny_vit_21m_512 in registry with controlnet_aux.segment_anything.modeling.tiny_vit_sam.tiny_vit_21m_512. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  return register_model(fn_wrapper)\n",
      "/workspace/ai-toolkit/extensions_built_in/sd_trainer/SDTrainer.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"type\": \"sd_trainer\",\n",
      "    \"training_folder\": \"model_A_output_lower_lr\",\n",
      "    \"performance_log_every\": 100,\n",
      "    \"device\": \"cuda:0\",\n",
      "    \"trigger_word\": \"model_A\",\n",
      "    \"network\": {\n",
      "        \"type\": \"lora\",\n",
      "        \"linear\": 64,\n",
      "        \"linear_alpha\": 64\n",
      "    },\n",
      "    \"save\": {\n",
      "        \"dtype\": \"float16\",\n",
      "        \"save_every\": 100,\n",
      "        \"max_step_saves_to_keep\": 30\n",
      "    },\n",
      "    \"datasets\": [\n",
      "        {\n",
      "            \"folder_path\": \"model_A\",\n",
      "            \"caption_ext\": \"txt\",\n",
      "            \"caption_dropout_rate\": 0.005,\n",
      "            \"shuffle_tokens\": false,\n",
      "            \"cache_latents_to_disk\": true,\n",
      "            \"resolution\": [\n",
      "                768,\n",
      "                1024\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"train\": {\n",
      "        \"batch_size\": 8,\n",
      "        \"steps\": 3000,\n",
      "        \"gradient_accumulation_steps\": 1,\n",
      "        \"train_unet\": true,\n",
      "        \"train_text_encoder\": false,\n",
      "        \"content_or_style\": \"balanced\",\n",
      "        \"gradient_checkpointing\": true,\n",
      "        \"noise_scheduler\": \"flowmatch\",\n",
      "        \"optimizer\": \"adamw8bit\",\n",
      "        \"lr\": 0.0001,\n",
      "        \"lr_scheduler\": \"cosine\",\n",
      "        \"scheduler_params\": {\n",
      "            \"T_max\": 3000,\n",
      "            \"eta_min\": 5e-06\n",
      "        },\n",
      "        \"ema_config\": {\n",
      "            \"use_ema\": true,\n",
      "            \"ema_decay\": 0.99\n",
      "        },\n",
      "        \"dtype\": \"bf16\"\n",
      "    },\n",
      "    \"model\": {\n",
      "        \"name_or_path\": \"black-forest-labs/FLUX.1-dev\",\n",
      "        \"is_flux\": true,\n",
      "        \"quantize\": true\n",
      "    },\n",
      "    \"sample\": {\n",
      "        \"sampler\": \"flowmatch\",\n",
      "        \"sample_every\": 100,\n",
      "        \"width\": 768,\n",
      "        \"height\": 768,\n",
      "        \"prompts\": [\n",
      "            \"A portrait of male model model_A wearing a red sweater.\",\n",
      "            \"A male model, model_A, sits with a poised and relaxed demeanor, one arm resting on the chairs arm, dressed in a sleek dark suit paired with a crisp white shirt. His tie displays a subtle pattern, adding a touch of elegance. The plain, light-colored background keeps the focus on his attire\"\n",
      "        ],\n",
      "        \"neg\": \"\",\n",
      "        \"seed\": 42,\n",
      "        \"walk_seed\": true,\n",
      "        \"guidance_scale\": 4,\n",
      "        \"sample_steps\": 20\n",
      "    }\n",
      "}\n",
      "Using EMA\n",
      "\n",
      "#############################################\n",
      "# Running job: model_A_lora_v1\n",
      "#############################################\n",
      "\n",
      "\n",
      "Running  1 process\n",
      "Loading Flux model\n",
      "Loading transformer\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b479de0fc4834b4097b848bd25968eb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantizing transformer\n",
      "Loading vae\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading t5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40dc2bb04fb54a96ac10ae379eb3c612",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be605c08209c43baaa55b708a7905992",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantizing T5\n",
      "Loading clip\n",
      "making pipe\n",
      "preparing\n",
      "create LoRA network. base dim (rank): 64, alpha: 64\n",
      "neuron dropout: p=None, rank dropout: p=None, module dropout: p=None\n",
      "create LoRA for Text Encoder: 0 modules.\n",
      "create LoRA for U-Net: 494 modules.\n",
      "enable LoRA for U-Net\n",
      "Dataset: model_A\n",
      "  -  Preprocessing image dimensions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 28597.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -  Found 15 images\n",
      "Bucket sizes for model_A:\n",
      "576x832: 3 files\n",
      "576x960: 1 files\n",
      "640x768: 11 files\n",
      "3 buckets made\n",
      "Caching latents for model_A\n",
      " - Saving latents to disk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Caching latents to disk: 100%|██████████| 15/15 [00:00<00:00, 10907.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: model_A\n",
      "  -  Preprocessing image dimensions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 34740.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -  Found 15 images\n",
      "Bucket sizes for model_A:\n",
      "832x1152: 3 files\n",
      "768x1344: 1 files\n",
      "896x1088: 11 files\n",
      "3 buckets made\n",
      "Caching latents for model_A\n",
      " - Saving latents to disk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Caching latents to disk: 100%|██████████| 15/15 [00:00<00:00, 23224.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating baseline samples before training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model_A_lora_v1:   0%|          | 0/3000 [00:00<?, ?it/s]       /usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n",
      "model_A_lora_v1:   3%|▎         | 99/3000 [22:56<6:59:21,  8.67s/it, lr: 1.0e-04 loss: 2.821e-01] \n",
      "Generating Images:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Generating Images:  50%|█████     | 1/2 [00:21<00:21, 21.66s/it]\u001b[A\n",
      "Generating Images: 100%|██████████| 2/2 [00:43<00:00, 21.64s/it]\u001b[A\n",
      "model_A_lora_v1:   3%|▎         | 99/3000 [22:56<6:59:21,  8.67s/it, lr: 1.0e-04 loss: 2.821e-01]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving at step 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model_A_lora_v1:   3%|▎         | 99/3000 [23:14<6:59:21,  8.67s/it, lr: 1.0e-04 loss: 2.821e-01]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to model_A_output_lower_lr/model_A_lora_v1/optimizer.pt\n",
      "\n",
      "Timer 'model_A_lora_v1 Timer':\n",
      " - 10.2460s avg - train_loop, num = 10\n",
      " - 6.5046s avg - backward, num = 10\n",
      " - 2.8128s avg - predict_unet, num = 10\n",
      " - 0.4542s avg - calculate_loss, num = 10\n",
      " - 0.4528s avg - reset_batch, num = 10\n",
      " - 0.2751s avg - optimizer_step, num = 10\n",
      " - 0.1008s avg - encode_prompt, num = 10\n",
      " - 0.0056s avg - get_batch, num = 10\n",
      " - 0.0019s avg - preprocess_batch, num = 10\n",
      " - 0.0012s avg - prepare_noise, num = 10\n",
      " - 0.0005s avg - prepare_latents, num = 10\n",
      " - 0.0004s avg - batch_cleanup, num = 10\n",
      " - 0.0001s avg - grad_setup, num = 10\n",
      " - 0.0000s avg - prepare_prompt, num = 10\n",
      " - 0.0000s avg - scheduler_step, num = 10\n",
      " - 0.0000s avg - log_to_tensorboard, num = 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model_A_lora_v1:   7%|▋         | 199/3000 [46:42<11:36:04, 14.91s/it, lr: 9.9e-05 loss: 1.825e-01]\n",
      "Generating Images:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Generating Images:  50%|█████     | 1/2 [00:21<00:21, 21.66s/it]\u001b[A\n",
      "Generating Images: 100%|██████████| 2/2 [00:43<00:00, 21.64s/it]\u001b[A\n",
      "model_A_lora_v1:   7%|▋         | 199/3000 [46:42<11:36:04, 14.91s/it, lr: 9.9e-05 loss: 1.825e-01]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving at step 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model_A_lora_v1:   7%|▋         | 199/3000 [47:02<11:36:04, 14.91s/it, lr: 9.9e-05 loss: 1.825e-01]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to model_A_output_lower_lr/model_A_lora_v1/optimizer.pt\n",
      "\n",
      "Timer 'model_A_lora_v1 Timer':\n",
      " - 16.3556s avg - train_loop, num = 10\n",
      " - 10.4949s avg - backward, num = 10\n",
      " - 4.4042s avg - predict_unet, num = 10\n",
      " - 0.7213s avg - calculate_loss, num = 10\n",
      " - 0.5081s avg - reset_batch, num = 10\n",
      " - 0.3977s avg - optimizer_step, num = 10\n",
      " - 0.1345s avg - encode_prompt, num = 10\n",
      " - 0.0089s avg - get_batch, num = 10\n",
      " - 0.0025s avg - preprocess_batch, num = 10\n",
      " - 0.0014s avg - prepare_noise, num = 10\n",
      " - 0.0009s avg - prepare_latents, num = 10\n",
      " - 0.0006s avg - batch_cleanup, num = 10\n",
      " - 0.0002s avg - grad_setup, num = 10\n",
      " - 0.0000s avg - prepare_prompt, num = 10\n",
      " - 0.0000s avg - scheduler_step, num = 10\n",
      " - 0.0000s avg - log_to_tensorboard, num = 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model_A_lora_v1:  10%|▉         | 299/3000 [1:09:08<8:09:19, 10.87s/it, lr: 9.8e-05 loss: 2.468e-01] \n",
      "Generating Images:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Generating Images:  50%|█████     | 1/2 [00:21<00:21, 21.63s/it]\u001b[A\n",
      "Generating Images: 100%|██████████| 2/2 [00:43<00:00, 21.64s/it]\u001b[A\n",
      "model_A_lora_v1:  10%|▉         | 299/3000 [1:09:08<8:09:19, 10.87s/it, lr: 9.8e-05 loss: 2.468e-01]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving at step 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model_A_lora_v1:  10%|▉         | 299/3000 [1:09:31<8:09:19, 10.87s/it, lr: 9.8e-05 loss: 2.468e-01]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to model_A_output_lower_lr/model_A_lora_v1/optimizer.pt\n",
      "\n",
      "Timer 'model_A_lora_v1 Timer':\n",
      " - 11.0953s avg - train_loop, num = 10\n",
      " - 7.0215s avg - backward, num = 10\n",
      " - 3.0643s avg - predict_unet, num = 10\n",
      " - 0.4921s avg - calculate_loss, num = 10\n",
      " - 0.4679s avg - reset_batch, num = 10\n",
      " - 0.2902s avg - optimizer_step, num = 10\n",
      " - 0.1197s avg - encode_prompt, num = 10\n",
      " - 0.0101s avg - get_batch, num = 10\n",
      " - 0.0022s avg - preprocess_batch, num = 10\n",
      " - 0.0014s avg - prepare_noise, num = 10\n",
      " - 0.0005s avg - prepare_latents, num = 10\n",
      " - 0.0004s avg - batch_cleanup, num = 10\n",
      " - 0.0002s avg - grad_setup, num = 10\n",
      " - 0.0000s avg - prepare_prompt, num = 10\n",
      " - 0.0000s avg - scheduler_step, num = 10\n",
      " - 0.0000s avg - log_to_tensorboard, num = 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model_A_lora_v1:  13%|█▎        | 399/3000 [1:32:18<10:35:24, 14.66s/it, lr: 9.6e-05 loss: 1.994e-01]\n",
      "Generating Images:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Generating Images:  50%|█████     | 1/2 [00:21<00:21, 21.67s/it]\u001b[A\n",
      "Generating Images: 100%|██████████| 2/2 [00:43<00:00, 21.64s/it]\u001b[A\n",
      "model_A_lora_v1:  13%|█▎        | 399/3000 [1:32:18<10:35:24, 14.66s/it, lr: 9.6e-05 loss: 1.994e-01]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving at step 400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model_A_lora_v1:  13%|█▎        | 399/3000 [1:32:57<10:35:24, 14.66s/it, lr: 9.6e-05 loss: 1.994e-01]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to model_A_output_lower_lr/model_A_lora_v1/optimizer.pt\n",
      "\n",
      "Timer 'model_A_lora_v1 Timer':\n",
      " - 12.5329s avg - train_loop, num = 10\n",
      " - 7.9690s avg - backward, num = 10\n",
      " - 3.4031s avg - predict_unet, num = 10\n",
      " - 0.5370s avg - calculate_loss, num = 10\n",
      " - 0.4985s avg - reset_batch, num = 10\n",
      " - 0.3231s avg - optimizer_step, num = 10\n",
      " - 0.1141s avg - encode_prompt, num = 10\n",
      " - 0.0072s avg - get_batch, num = 10\n",
      " - 0.0021s avg - preprocess_batch, num = 10\n",
      " - 0.0013s avg - prepare_noise, num = 10\n",
      " - 0.0005s avg - prepare_latents, num = 10\n",
      " - 0.0004s avg - batch_cleanup, num = 10\n",
      " - 0.0002s avg - grad_setup, num = 10\n",
      " - 0.0000s avg - prepare_prompt, num = 10\n",
      " - 0.0000s avg - scheduler_step, num = 10\n",
      " - 0.0000s avg - log_to_tensorboard, num = 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model_A_lora_v1:  17%|█▋        | 499/3000 [1:55:27<5:36:55,  8.08s/it, lr: 9.3e-05 loss: 1.964e-01] \n",
      "Generating Images:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Generating Images:  50%|█████     | 1/2 [00:21<00:21, 21.66s/it]\u001b[A\n",
      "Generating Images: 100%|██████████| 2/2 [00:43<00:00, 21.66s/it]\u001b[A\n",
      "model_A_lora_v1:  17%|█▋        | 499/3000 [1:55:27<5:36:55,  8.08s/it, lr: 9.3e-05 loss: 1.964e-01]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving at step 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model_A_lora_v1:  17%|█▋        | 499/3000 [1:55:53<5:36:55,  8.08s/it, lr: 9.3e-05 loss: 1.964e-01]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to model_A_output_lower_lr/model_A_lora_v1/optimizer.pt\n",
      "\n",
      "Timer 'model_A_lora_v1 Timer':\n",
      " - 12.0051s avg - train_loop, num = 10\n",
      " - 7.6759s avg - backward, num = 10\n",
      " - 3.2826s avg - predict_unet, num = 10\n",
      " - 0.5163s avg - calculate_loss, num = 10\n",
      " - 0.4757s avg - reset_batch, num = 10\n",
      " - 0.3168s avg - optimizer_step, num = 10\n",
      " - 0.1082s avg - encode_prompt, num = 10\n",
      " - 0.0033s avg - get_batch, num = 10\n",
      " - 0.0018s avg - preprocess_batch, num = 10\n",
      " - 0.0011s avg - prepare_noise, num = 10\n",
      " - 0.0005s avg - prepare_latents, num = 10\n",
      " - 0.0003s avg - batch_cleanup, num = 10\n",
      " - 0.0002s avg - grad_setup, num = 10\n",
      " - 0.0000s avg - scheduler_step, num = 10\n",
      " - 0.0000s avg - prepare_prompt, num = 10\n",
      " - 0.0000s avg - log_to_tensorboard, num = 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model_A_lora_v1:  20%|█▉        | 599/3000 [2:18:54<9:48:22, 14.70s/it, lr: 9.0e-05 loss: 1.711e-01] \n",
      "Generating Images:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Generating Images:  50%|█████     | 1/2 [00:21<00:21, 21.67s/it]\u001b[A\n",
      "Generating Images: 100%|██████████| 2/2 [00:43<00:00, 21.65s/it]\u001b[A\n",
      "model_A_lora_v1:  20%|█▉        | 599/3000 [2:18:54<9:48:22, 14.70s/it, lr: 9.0e-05 loss: 1.711e-01]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving at step 600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model_A_lora_v1:  20%|█▉        | 599/3000 [2:19:33<9:48:22, 14.70s/it, lr: 9.0e-05 loss: 1.711e-01]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to model_A_output_lower_lr/model_A_lora_v1/optimizer.pt\n",
      "\n",
      "Timer 'model_A_lora_v1 Timer':\n",
      " - 16.8623s avg - train_loop, num = 10\n",
      " - 10.8191s avg - backward, num = 10\n",
      " - 4.5630s avg - predict_unet, num = 10\n",
      " - 0.7400s avg - calculate_loss, num = 10\n",
      " - 0.4441s avg - reset_batch, num = 10\n",
      " - 0.4069s avg - optimizer_step, num = 10\n",
      " - 0.1448s avg - encode_prompt, num = 10\n",
      " - 0.0064s avg - get_batch, num = 10\n",
      " - 0.0023s avg - preprocess_batch, num = 10\n",
      " - 0.0014s avg - prepare_noise, num = 10\n",
      " - 0.0006s avg - prepare_latents, num = 10\n",
      " - 0.0004s avg - batch_cleanup, num = 10\n",
      " - 0.0002s avg - grad_setup, num = 10\n",
      " - 0.0000s avg - prepare_prompt, num = 10\n",
      " - 0.0000s avg - scheduler_step, num = 10\n",
      " - 0.0000s avg - log_to_tensorboard, num = 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model_A_lora_v1:  22%|██▏       | 647/3000 [2:29:21<6:26:45,  9.86s/it, lr: 8.9e-05 loss: 2.198e-01] "
     ]
    }
   ],
   "source": [
    "# Start the training process\n",
    "run_job(job_to_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3BPdirqiq5d-"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import FluxPipeline\n",
    "\n",
    "base_model = \"black-forest-labs/FLUX.1-dev\"\n",
    "#lora_weights = \"/content/drive/MyDrive/output_ml6_icons_lora32/ml6_lora_v1/ml6_lora_v1_000001900.safetensors\"\n",
    "lora_weights = \"/content/drive/MyDrive/lora_fashion/model_A_output/model_A_lora_v1/model_A_lora_v1_000000700.safetensors\"\n",
    "\n",
    "pipe = FluxPipeline.from_pretrained(base_model, torch_dtype=torch.bfloat16)\n",
    "pipe.load_lora_weights(lora_weights)\n",
    "\n",
    "pipe.fuse_lora(lora_scale=0.8)\n",
    "pipe.to(\"cuda\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
